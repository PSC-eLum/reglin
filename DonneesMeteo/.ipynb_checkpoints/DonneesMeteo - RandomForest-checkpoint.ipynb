{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DonneesMeteo.txt\",delim_whitespace=True, low_memory=False, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#time = temp = pd.DatetimeIndex(df1['DT_local'])\n",
    "date = pd.DatetimeIndex(pd.to_datetime(df['Date'], format=\"%Y%m%d\"))\n",
    "df['MONTH'] = date.month\n",
    "df['DAY'] = date.day\n",
    "df['YEAR'] = date.year\n",
    "df['DOY'] = date.dayofyear\n",
    "#Version arrondie à la minute de la ligne du dessous : num = pd.to_datetime(pd.Series.round(df['hh(UTC)']*3600)*1000000000)\n",
    "hh = pd.DatetimeIndex(pd.to_datetime(df['hh(UTC)']*3600*1000000000))\n",
    "df['HOUR'] = hh.hour\n",
    "df['MINUTE'] = hh.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conversion des heures de la journee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent se concentrer sur la prédiction de :\n",
    "    - puissance\n",
    "Selon\n",
    "    - T\n",
    "    - vent\n",
    "    - skycover\n",
    "    - precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "colsX = ['DOY',\n",
    "    'Date',\n",
    " 'hh(UTC)',\n",
    " 'Tp1(C)',\n",
    " 'Tp2(C)',\n",
    " 'IrrPOA(W/m2)',\n",
    " 'Gz2(W/m2)',\n",
    " 'Drz2(W/m2)',\n",
    " 'Dfz2(W/m2)',\n",
    " 'IRz2(W/m2)',\n",
    " 'T(C)',\n",
    " 'WS(m/s)',\n",
    " 'WD(deg)',\n",
    " 'mpGz1(W/m2)',\n",
    " 'IRz1dn(W/m2)',\n",
    " 'IRz1up(W/m2)',\n",
    " 'mpT(C)',\n",
    " 'mpWS(m/s)',\n",
    " 'mpWD(deg)',\n",
    " 'SZA(deg)',\n",
    " 'SAA(deg)']\n",
    "#colsX = [\"DOY\", \"hh(UTC)\", \"IrrPOA(W/m2)\"]\n",
    "colsY = [\"P1(W)\", \"P2(W)\"]\n",
    "nDOY = 0\n",
    "nhh = 2\n",
    "#print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "import sklearn.preprocessing as pp #pour les scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare(df,colsX,colsY):\n",
    "    #Split the treated data between X and y\n",
    "    Z = vireNan(df[colsX+colsY])\n",
    "    deb = 0\n",
    "    sep = len(colsX)#separteur entre les X et les Y\n",
    "    fin = sep+len(colsY)\n",
    "    X=Z[:,deb:sep]\n",
    "    y=Z[:,sep:fin]\n",
    "    return X,y\n",
    "\n",
    "import numpy as np\n",
    "def vireNan(Z) :\n",
    "    # Load the dataset\n",
    "    Z = np.array(Z).astype(np.float)\n",
    "\n",
    "    #Remove nan and infinite values\n",
    "    masknan = ~np.any(np.isnan(Z), axis=1)\n",
    "    Z = Z[masknan]\n",
    "    maskfin = np.any(np.isfinite(Z), axis=1)\n",
    "    Z = Z[maskfin]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preparer (nan, découpe)\n",
    "X,y = prepare(df,colsX,colsY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoupe(X,y) :\n",
    "    X_train, X_1, y_train, y_1 = cv.train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "    X_cv, X_test, y_cv, y_test = cv.train_test_split(X_1, y_1, test_size=0.1, random_state=0)\n",
    "    return X_train, X_cv, X_test, y_train, y_cv, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Découper\n",
    "X_train, X_cv, X_test, y_train, y_cv, y_test = decoupe(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variable globales\n",
    "fsX = pp.StandardScaler()\n",
    "fsy = pp.StandardScaler()\n",
    "def featureScale(X_train, X_cv, X_test, y_train, y_cv, y_test) :\n",
    "    #feature scaling inti\n",
    "    fsX.fit(X_train)\n",
    "    X_train = fsX.transform(X_train)\n",
    "    X_cv = fsX.transform(X_cv)\n",
    "    X_test = fsX.transform(X_test)\n",
    "    \n",
    "    #fsy.fit(y_train)\n",
    "    #y_train = fsy.transform(y_train)\n",
    "    #y_cv = fsy.transform(y_cv)\n",
    "    #y_test = fsy.transform(y_test)\n",
    "    \n",
    "    return X_train, X_cv, X_test, y_train, y_cv, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaler par rapport au train\n",
    "X_train, X_cv, X_test, y_train, y_cv, y_test = featureScale(X_train, X_cv, X_test, y_train, y_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonctions communes à toutes les régressions\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rms(Y1,Y2):\n",
    "    print(np.sqrt(np.mean(((Y1 - Y2)/Y2)**2)))\n",
    "    #np.sqrt(np.mean((Y1 - Y2)**2))\n",
    "    #Y2 fait office de valeur de référence\n",
    "    return np.sqrt(np.mean(((Y1 - Y2)/Y2)**2))\n",
    "\n",
    "def randomforest(n,X,Y,X_test):\n",
    "    clf= RandomForestRegressor(n_estimators=n)\n",
    "    clf.fit(X,Y)\n",
    "    y_test  = clf.predict(X_test)\n",
    "    y_train = clf.predict(X)\n",
    "    return y_train, y_test\n",
    "\n",
    "def plotRMS(RMS):\n",
    "    plt.scatter(RMS[:,0],RMS[:,1], color=\"blue\")\n",
    "    plt.scatter(RMS[:,0],RMS[:,2], color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomforestcrossovern(nArray, X_train, X_cv, y_train, y_cv):\n",
    "    #Conversion\n",
    "    nArray = np.array(nArray).astype(np.integer)\n",
    "    #tableau avec les valeurs d'erreur\n",
    "    RMS=np.zeros((nArray.size,3))\n",
    "    \n",
    "    i=0\n",
    "    for n in nArray:\n",
    "        y_train_, y_cv_=randomforest(n,X_train,y_train,X_cv)\n",
    "        RMS[i,0]= n\n",
    "        RMS[i,1]= rms(y_cv_    ,y_cv)\n",
    "        RMS[i,2]= rms(y_train_ ,y_train)\n",
    "        i+=1\n",
    "        print(\"n \",n)\n",
    "    plotRMS(RMS)\n",
    "    \n",
    "    \n",
    "    return RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.7696594427\n",
      "66.8377399381\n",
      "n  1\n",
      "66.9485595115\n",
      "66.9406785346\n",
      "n  4\n",
      "66.7028070175\n",
      "66.9149772962\n",
      "n  10\n",
      "66.6905202958\n",
      "66.9438482972\n",
      "n  40\n",
      "66.7260435157\n",
      "67.01019484\n",
      "n  100\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "#Pour plusieurs n ? on prends n =30, suffisant, erreur de 0.2\n",
    "nArray = [1,4,10,40,100]\n",
    "#Cross sur les nArray\n",
    "randomforestcrossovern(nArray, X_train, X_cv, y_train, y_cv)\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertirExtensif(deb,fin,pas,X):\n",
    "    nCols = int((fin-deb)/pas)\n",
    "    m = np.shape(X)[0]\n",
    "    deb = deb * np.ones((m))#pour soustraction\n",
    "    y = np.zeros((m,nCols))\n",
    "    #print(\"nCols\",nCols)\n",
    "    \n",
    "    #conversion pour les index\n",
    "    idxArray = np.divide((X-deb),pas)\n",
    "    #virer les cas ou egal a fin\n",
    "    maxVal = (fin-deb)/pas\n",
    "    idxArray = idxArray - (idxArray >= maxVal)*maxVal\n",
    "    #print(X)\n",
    "    #print(\"idxArray\",idxArray)\n",
    "    \n",
    "    l = 0\n",
    "    for idx in idxArray:\n",
    "        y[l,idx] = 1\n",
    "        l+=1\n",
    "    #print(y)\n",
    "    return y\n",
    "\n",
    "def convertirExtensifEnPlace(nCol,deb,fin,pas,X):\n",
    "    return np.append( np.delete(X, (nCol), axis=1) , convertirExtensif(deb,fin,pas,X[:,nCol]) , (1))#(1) pour l'axe \"col\"\n",
    "    \n",
    "\n",
    "def randomforestcrossoverext(nCol,deb,fin,pasArray,n, X_train, X_cv, y_train, y_cv):\n",
    "    pasArray = np.array(pasArray)\n",
    "    RMS=np.zeros((pasArray.size,3))\n",
    "    \n",
    "    i=0\n",
    "    for pas in pasArray:\n",
    "        #print(\"\")\n",
    "        print(\"pas\",pas)\n",
    "        #print(\"shape X_train\",np.shape(X_train))\n",
    "        #Transformation data\n",
    "        X_train_ =convertirExtensifEnPlace(nCol,deb,fin,pas,X_train)\n",
    "        X_cv_    =convertirExtensifEnPlace(nCol,deb,fin,pas,X_cv)\n",
    "        #print(np.shape(X_train_))\n",
    "        #print(np.shape(X_cv_))\n",
    "        #print(np.shape(y_train))\n",
    "        y_train_, y_cv_= randomforest(n,X_train_,y_train,X_cv_)\n",
    "        r = rms(y_,y_cv)\n",
    "        RMS[i,0]=pas\n",
    "        RMS[i,1]= rms(y_cv_    ,y_cv)\n",
    "        RMS[i,2]= rms(y_train_ ,y_train)\n",
    "        i+=1\n",
    "    plotRMS(RMS)\n",
    "    return RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pas 1\n",
      "pas 10\n",
      "pas 30\n",
      "pas 60\n",
      "pas 100\n",
      "pas 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1.        ,    0.18934399],\n",
       "       [  10.        ,    0.19063415],\n",
       "       [  30.        ,    0.19383553],\n",
       "       [  60.        ,    0.19136682],\n",
       "       [ 100.        ,    0.18916937],\n",
       "       [ 150.        ,    0.18798213]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=30\n",
    "#Cross sur les differentes extensions\n",
    "#d'abord DOY\n",
    "deb =0\n",
    "fin =366\n",
    "pas = [1,10,30,60,100,150]\n",
    "randomforestcrossoverext(nDOY,deb,fin,pas,n, X_train, X_cv, y_train, y_cv)\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pas 0.1\n",
      "pas 0.4\n",
      "pas 7.8\n",
      "pas 1.0\n",
      "pas 3.0\n",
      "pas 6.0\n",
      "pas 9.0\n",
      "pas 12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.1       ,   0.19081612],\n",
       "       [  0.4       ,   0.19112152],\n",
       "       [  7.8       ,   0.1910804 ],\n",
       "       [  1.        ,   0.18938497],\n",
       "       [  3.        ,   0.19013104],\n",
       "       [  6.        ,   0.18806245],\n",
       "       [  9.        ,   0.1910899 ],\n",
       "       [ 12.        ,   0.19123995]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=30\n",
    "#Cross sur les differentes extensions\n",
    "#d'abord DOY\n",
    "deb =0\n",
    "fin =24\n",
    "pas = [0.1,0.4,7.8,1,3,6,9,12]\n",
    "randomforestcrossoverext(nhh,deb,fin,pas,n, X_train, X_cv, y_train, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=1\n",
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "print(a)\n",
    "print(np.delete(a,(n),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot outputs 2D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plotterIterations(X,nX,nIt,y,ny) :\n",
    "    #On se ramène à des journées\n",
    "    EltIteration = X[:,nIt]\n",
    "    Iterations = np.unique(EltIteration)\n",
    "    print(Iterations)\n",
    "\n",
    "    #Gérer plusieurs couleurs\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(Iterations)))\n",
    "\n",
    "    for k,c in zip(Iterations,colors)  :\n",
    "        #On prend que le jour\n",
    "        condition = EltIteration == k #entre 60 et 153\n",
    "        xPlot = np.extract(condition, X[:,nX])\n",
    "        yPlot = np.extract(condition, y[:,ny])\n",
    "        plt.scatter(xPlot,yPlot, color=c,s=2)\n",
    "        #sort\n",
    "        #print(np.concatenate(xPlot,yPlot))\n",
    "        #z = np.sort(np.concatenate(xPlot,yPlot),0)\n",
    "        #plt.plot(z[:,0], z[:,1], color=c,linewidth=2)\n",
    "        #print(k)\n",
    "        #print(xPlot)\n",
    "        #print(yPlot)\n",
    "        #print(z[:,0])\n",
    "        #print(z[:,1])\n",
    "        #break\n",
    "\n",
    "    #plt.plot(X_test, regr.predict(X_test), color='blue',linewidth=3)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.title('')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
