{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DonneesMeteo.txt\",delim_whitespace=True, low_memory=False, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#time = temp = pd.DatetimeIndex(df1['DT_local'])\n",
    "date = pd.DatetimeIndex(pd.to_datetime(df['Date'], format=\"%Y%m%d\"))\n",
    "df['MONTH'] = date.month\n",
    "df['DAY'] = date.day\n",
    "df['YEAR'] = date.year\n",
    "#Version arrondie à la minute de la ligne du dessous : num = pd.to_datetime(pd.Series.round(df['hh(UTC)']*3600)*1000000000)\n",
    "hh = pd.DatetimeIndex(pd.to_datetime(df['hh(UTC)']*3600*1000000000))\n",
    "df['HOUR'] = hh.hour\n",
    "df['MINUTE'] = hh.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent se concentrer sur la prédiction de :\n",
    "    - puissance\n",
    "Selon\n",
    "    - T\n",
    "    - vent\n",
    "    - skycover\n",
    "    - precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "colsX = ['DAY',\n",
    "    'Date',\n",
    " 'hh(UTC)',\n",
    " 'Tp1(C)',\n",
    " 'Tp2(C)',\n",
    " 'IrrPOA(W/m2)',\n",
    " 'Gz2(W/m2)',\n",
    " 'Drz2(W/m2)',\n",
    " 'Dfz2(W/m2)',\n",
    " 'IRz2(W/m2)',\n",
    " 'T(C)',\n",
    " 'WS(m/s)',\n",
    " 'WD(deg)',\n",
    " 'mpGz1(W/m2)',\n",
    " 'IRz1dn(W/m2)',\n",
    " 'IRz1up(W/m2)',\n",
    " 'mpT(C)',\n",
    " 'mpWS(m/s)',\n",
    " 'mpWD(deg)',\n",
    " 'SZA(deg)',\n",
    " 'SAA(deg)']\n",
    "#colsX = [\"DayPart\", \"T(C)\", ]\n",
    "colsY = [\"P1(W)\", \"P2(W)\"]\n",
    "#print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preparer (nan, découpe)\n",
    "X,y = prepare(df,colsX,colsY)\n",
    "#Découper\n",
    "X_train, X_cv, X_test, y_train, y_cv, y_test = decoupe(X,y)\n",
    "#scaler\n",
    "X_train, X_cv, X_test, y_train, y_cv, y_test = featureScale(X_train, X_cv, X_test, y_train, y_cv, y_test)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 0.03\n",
      "Variance score: 0.97\n",
      "-1.8050023185\n",
      "-1.56185620589\n",
      "-1.44028314959\n",
      "-1.31871009329\n",
      "-1.19713703698\n",
      "-1.07556398068\n",
      "-0.953990924375\n",
      "-0.832417868071\n",
      "-0.710844811767\n",
      "-0.589271755463\n",
      "-0.467698699159\n",
      "-0.346125642856\n",
      "-0.224552586552\n",
      "-0.102979530248\n",
      "0.0185935260558\n",
      "0.14016658236\n",
      "0.261739638663\n",
      "0.383312694967\n",
      "0.504885751271\n",
      "0.626458807575\n",
      "0.748031863879\n",
      "0.869604920182\n",
      "0.991177976486\n",
      "1.11275103279\n",
      "1.23432408909\n",
      "1.3558971454\n",
      "1.4774702017\n",
      "1.59904325801\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "from sklearn import ensemble\n",
    "regr = sklearn.ensemble.RandomForestRegressor()\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((regr.predict(X_test) - y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotterIterations(X_test,2,1,y_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot outputs 2D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plotterIterations(X,nX,nIt,y,ny) :\n",
    "    #On se ramène à des journées\n",
    "    EltIteration = X[:,nIt]\n",
    "    Iterations = np.unique(EltIteration)\n",
    "\n",
    "    #Gérer plusieurs couleurs\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(Iterations)))\n",
    "\n",
    "    for k,c in zip(Iterations,colors)  :\n",
    "        print(k)\n",
    "        #On prend que le jour\n",
    "        condition = EltIteration == k #entre 60 et 153\n",
    "        xPlot = np.extract(condition, X[:,nX])\n",
    "        yPlot = np.extract(condition, y[:,ny])\n",
    "        plt.scatter(xPlot, yPlot, color=c,linewidth=2)\n",
    "\n",
    "    #plt.plot(X_test, regr.predict(X_test), color='blue',linewidth=3)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    #plt.xlabel(colsX[nX])\n",
    "    #plt.ylabel(colsY[nY])\n",
    "    plt.title('')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "import sklearn.preprocessing as pp #pour les scaling\n",
    "\n",
    "def rms(Y1,Y2):\n",
    "    return np.sqrt(np.mean((Y1 - Y2)**2))\n",
    "    \n",
    "def randomforestcross(X,Y):\n",
    "    X_train, X_1, y_train, y_1 = cv.train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "    X_cr, X_test, y_cr, y_test = cv.train_test_split(X_1, y_1, test_size=0.5, random_state=0)\n",
    "    RMS=np.zeros((100,2))\n",
    "    \n",
    "    for i in range(1,25):\n",
    "        y_=randomforest(i,X_train,y_train,X_cr)\n",
    "        r=rms(y_,y_cr)\n",
    "        RMS[i,0]=i\n",
    "        RMS[i,1]=r\n",
    "    plt.scatter(RMS[:,0],RMS[:,1])\n",
    "    plt.show()\n",
    "    L = [X_train, y_train, X_test, y_test]\n",
    "    return L \n",
    "\n",
    "def randomforest(n,X,Y,X_t):\n",
    "    clf= RandomForestRegressor(n_estimators=n)\n",
    "    clf.fit(X,Y)\n",
    "    y_=clf.predict(X_t)\n",
    "    return y_\n",
    "\n",
    "def gradientcross(X,Y):\n",
    "    X_train, X_cv, X_test, y_train, y_cv, y_test = decoupe(X,y)\n",
    "    RMS=np.zeros((250,2))\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        i = i * 10 + 100\n",
    "        y_=gradient(i,X_train,y_train,X_cr)\n",
    "        r=rms(y_,y_cr)\n",
    "        RMS[i,0]=i\n",
    "        RMS[i,1]=r\n",
    "    plt.scatter(RMS[:,0],RMS[:,1])\n",
    "    plt.show()\n",
    "    L = [X_train, y_train, X_test, y_test]\n",
    "    return L \n",
    "def gradient(n,X,Y,X_t):\n",
    "    clf= ensemble.GradientBoostingRegressor(n_estimators=n)\n",
    "    clf.fit(X,Y)\n",
    "    y_=clf.predict(X_t)\n",
    "    return y_\n",
    "\n",
    "\n",
    "def prepare(df,colsX,colsY):\n",
    "    #Split the treated data between X and y\n",
    "    Z = vireNan(df[colsX+colsY])\n",
    "    deb = 0\n",
    "    sep = len(colsX)#separteur entre les X et les Y\n",
    "    fin = sep+len(colsY)\n",
    "    X=Z[:,deb:sep]\n",
    "    y=Z[:,sep:fin]\n",
    "    return X,y\n",
    "\n",
    "import numpy as np\n",
    "def vireNan(Z) :\n",
    "    # Load the dataset\n",
    "    Z = np.array(Z).astype(np.float)\n",
    "\n",
    "    #Remove nan and infinite values\n",
    "    masknan = ~np.any(np.isnan(Z), axis=1)\n",
    "    Z = Z[masknan]\n",
    "    maskfin = np.any(np.isfinite(Z), axis=1)\n",
    "    Z = Z[maskfin]\n",
    "    return Z\n",
    "\n",
    "def decoupe(X,y) :\n",
    "    X_train, X_1, y_train, y_1 = cv.train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "    X_cv, X_test, y_cv, y_test = cv.train_test_split(X_1, y_1, test_size=0.1, random_state=0)\n",
    "    return X_train, X_cv, X_test, y_train, y_cv, y_test\n",
    "\n",
    "#variable globales\n",
    "fsX = pp.StandardScaler()\n",
    "fsy = pp.StandardScaler()\n",
    "def featureScale(X_train, X_cv, X_test, y_train, y_cv, y_test) :\n",
    "    #feature scaling inti\n",
    "    fsX.fit(X_train)\n",
    "    X_train = fsX.transform(X_train)\n",
    "    X_cv = fsX.transform(X_cv)\n",
    "    X_test = fsX.transform(X_test)\n",
    "    \n",
    "    fsy.fit(y_train)\n",
    "    y_train = fsy.transform(y_train)\n",
    "    y_cv = fsy.transform(y_cv)\n",
    "    y_test = fsy.transform(y_test)\n",
    "    \n",
    "    return X_train, X_cv, X_test, y_train, y_cv, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
